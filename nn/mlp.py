# autogenerated


import math

def sigmoid(x):
    return 1 / (1 + math.exp(-x))

class MLP:
    def __init__(self, input_size, hidden_size, output_size):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size

        self.hidden_weights = [[0.0] * hidden_size for _ in range(input_size)]
        self.hidden_bias = [0.0] * hidden_size

        self.output_weights = [[0.0] * output_size for _ in range(hidden_size)]
        self.output_bias = [0.0] * output_size

    def forward(self, inputs):
        hidden_layer = [sigmoid(sum(w * x for w, x in zip(self.hidden_weights[i], inputs)) + b) for i, b in enumerate(self.hidden_bias)]
        output_layer = [sigmoid(sum(w * h for w, h in zip(self.output_weights[i], hidden_layer)) + b) for i, b in enumerate(self.output_bias)]
        return output_layer

    def train(self, inputs, targets, learning_rate=0.1):
        hidden_layer = [sigmoid(sum(w * x for w, x in zip(self.hidden_weights[i], inputs)) + b) for i, b in enumerate(self.hidden_bias)]
        output_layer = [sigmoid(sum(w * h for w, h in zip(self.output_weights[i], hidden_layer)) + b) for i, b in enumerate(self.output_bias)]

        output_errors = [t - o for t, o in zip(targets, output_layer)]
        output_deltas = [o * (1 - o) * e for o, e in zip(output_layer, output_errors)]

        hidden_errors = [sum(self.output_weights[i][j] * output_deltas[j] for j in range(self.output_size)) for i in range(self.hidden_size)]
        hidden_deltas = [h * (1 - h) * e for h, e in zip(hidden_layer, hidden_errors)]

        self.output_weights = [[w + learning_rate * output_deltas[j] * hidden_layer[i] for j, w in enumerate(self.output_weights[i])] for i in range(self.hidden_size)]
        self.output_bias = [b + learning_rate * output_deltas[i] for i, b in enumerate(self.output_bias)]

        self.hidden_weights = [[w + learning_rate * hidden_deltas[j] * inputs[i] for j, w in enumerate(self.hidden_weights[i])] for i in range(self.input_size)]
        self.hidden_bias = [b + learning_rate * hidden_deltas[i] for i, b in enumerate(self.hidden_bias)]



